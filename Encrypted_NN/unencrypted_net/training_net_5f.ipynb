{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_net_5f.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "otwSch5JJnho",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "a7eb3738-3229-49c8-8adf-f1920d27caa5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532534816847,
          "user_tz": -60,
          "elapsed": 949,
          "user": {
            "displayName": "shreya garge",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "113769829546482680202"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "L_QLzh19KAl1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        " # Training Parameters\n",
        "learning_rate = 0.01\n",
        "num_steps = 10000\n",
        "batch_size = 120\n",
        "display_step = 100\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 784 # MNIST data input (img shape: 28*28)\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "dropout = 0.75 # Dropout, probability to keep units\n",
        "\n",
        "# tf Graph input\n",
        "X = tf.placeholder(tf.float32, [None, num_input])\n",
        "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
        "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F00e7kIyKG_X",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and square activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def meanpool2d(x, k=2):\n",
        "    \n",
        "    return tf.nn.avg_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
        "                          padding='SAME')\n",
        "\n",
        "# Create model\n",
        "def conv_net(x, weights, biases, dropout):\n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv1_ = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "    conv1_ = tf.square(conv1_)\n",
        "    conv1 = meanpool2d(conv1_, k=2)\n",
        "    \n",
        "    conv2_ = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    conv2 = meanpool2d(conv2_, k=2)\n",
        "    \n",
        "    fc1_ = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1_, weights['wd1']), biases['bd1'])\n",
        "    fc1 = tf.square(fc1)\n",
        "    # Apply Dropout\n",
        "    fc1_2 = tf.nn.dropout(fc1, dropout)\n",
        "    \n",
        "    check = {}\n",
        "    check['conv1'] = conv1_\n",
        "    check['conv1mp'] = conv1\n",
        "    check['conv2'] = conv2_\n",
        "    check['conv2mp'] = conv2\n",
        "    check['fc1_reshape'] = fc1_\n",
        "    check['fc1_wb'] = fc1\n",
        "    check['fc1_drp'] = fc1_2\n",
        "\n",
        "    # Output, class prediction\n",
        "    out = tf.add(tf.matmul(fc1_2, weights['out']), biases['out'])\n",
        "    return out, check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "F_iN2hNgKzhr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    # 5x5 conv, 1 input, 5 outputs\n",
        "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 5])),\n",
        "    # 5x5 conv, 5 inputs, 10 outputs\n",
        "    'wc2': tf.Variable(tf.random_normal([5, 5, 5, 10])),\n",
        "    # fully connected, 7*7*10 inputs, 128 outputs\n",
        "    'wd1': tf.Variable(tf.random_normal([7*7*10, 128])),\n",
        "    # 1024 inputs, 10 outputs (class prediction)\n",
        "    'out': tf.Variable(tf.random_normal([128, num_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'bc1': tf.Variable(tf.random_normal([5])),\n",
        "    'bc2': tf.Variable(tf.random_normal([10])),\n",
        "    'bd1': tf.Variable(tf.random_normal([128])),\n",
        "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
        "}\n",
        "\n",
        "\n",
        "# Construct model\n",
        "logits,verify = conv_net(X, weights, biases, keep_prob)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "    logits=logits, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "\n",
        "# Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()\n",
        "# Run the initializer\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NXrjN8KsMfzR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1768
        },
        "outputId": "22a97c39-cb2a-4a4f-eb50-8867be123256",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532534900909,
          "user_tz": -60,
          "elapsed": 59370,
          "user": {
            "displayName": "shreya garge",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "113769829546482680202"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "import numpy as np\n",
        "for step in range(1, num_steps+1):\n",
        "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
        "                                                                 Y: batch_y,\n",
        "                                                                 keep_prob: 1.0})\n",
        "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc))\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "\n",
        "# Calculate accuracy for 256 MNIST test images\n",
        "print(\"Testing Accuracy:\", \\\n",
        "    sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
        "                                  Y: mnist.test.labels[:256],\n",
        "                                  keep_prob: 1.0}))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, Minibatch Loss= 159074992.0000, Training Accuracy= 0.125\n",
            "Step 100, Minibatch Loss= 497969.1875, Training Accuracy= 0.867\n",
            "Step 200, Minibatch Loss= 363224.0625, Training Accuracy= 0.900\n",
            "Step 300, Minibatch Loss= 186837.8594, Training Accuracy= 0.892\n",
            "Step 400, Minibatch Loss= 243256.2656, Training Accuracy= 0.850\n",
            "Step 500, Minibatch Loss= 78208.9531, Training Accuracy= 0.925\n",
            "Step 600, Minibatch Loss= 103313.7891, Training Accuracy= 0.900\n",
            "Step 700, Minibatch Loss= 126782.6953, Training Accuracy= 0.908\n",
            "Step 800, Minibatch Loss= 80003.4062, Training Accuracy= 0.908\n",
            "Step 900, Minibatch Loss= 117584.2969, Training Accuracy= 0.883\n",
            "Step 1000, Minibatch Loss= 23355.2051, Training Accuracy= 0.950\n",
            "Step 1100, Minibatch Loss= 24589.8496, Training Accuracy= 0.942\n",
            "Step 1200, Minibatch Loss= 30010.2070, Training Accuracy= 0.925\n",
            "Step 1300, Minibatch Loss= 49054.7344, Training Accuracy= 0.900\n",
            "Step 1400, Minibatch Loss= 20765.3496, Training Accuracy= 0.933\n",
            "Step 1500, Minibatch Loss= 24749.9180, Training Accuracy= 0.908\n",
            "Step 1600, Minibatch Loss= 12686.7900, Training Accuracy= 0.942\n",
            "Step 1700, Minibatch Loss= 21827.5547, Training Accuracy= 0.917\n",
            "Step 1800, Minibatch Loss= 16893.5391, Training Accuracy= 0.933\n",
            "Step 1900, Minibatch Loss= 9956.6709, Training Accuracy= 0.950\n",
            "Step 2000, Minibatch Loss= 29082.0859, Training Accuracy= 0.900\n",
            "Step 2100, Minibatch Loss= 14059.2939, Training Accuracy= 0.917\n",
            "Step 2200, Minibatch Loss= 13322.4854, Training Accuracy= 0.925\n",
            "Step 2300, Minibatch Loss= 3669.2080, Training Accuracy= 0.975\n",
            "Step 2400, Minibatch Loss= 5354.7627, Training Accuracy= 0.950\n",
            "Step 2500, Minibatch Loss= 4703.5073, Training Accuracy= 0.942\n",
            "Step 2600, Minibatch Loss= 11764.4307, Training Accuracy= 0.958\n",
            "Step 2700, Minibatch Loss= 5359.5435, Training Accuracy= 0.967\n",
            "Step 2800, Minibatch Loss= 14861.1211, Training Accuracy= 0.908\n",
            "Step 2900, Minibatch Loss= 9367.8682, Training Accuracy= 0.950\n",
            "Step 3000, Minibatch Loss= 5502.0400, Training Accuracy= 0.967\n",
            "Step 3100, Minibatch Loss= 9744.0791, Training Accuracy= 0.917\n",
            "Step 3200, Minibatch Loss= 7461.8228, Training Accuracy= 0.950\n",
            "Step 3300, Minibatch Loss= 9178.4541, Training Accuracy= 0.942\n",
            "Step 3400, Minibatch Loss= 9618.9707, Training Accuracy= 0.933\n",
            "Step 3500, Minibatch Loss= 3700.8647, Training Accuracy= 0.942\n",
            "Step 3600, Minibatch Loss= 3684.6702, Training Accuracy= 0.950\n",
            "Step 3700, Minibatch Loss= 6432.1880, Training Accuracy= 0.975\n",
            "Step 3800, Minibatch Loss= 2305.4092, Training Accuracy= 0.950\n",
            "Step 3900, Minibatch Loss= 5316.5581, Training Accuracy= 0.975\n",
            "Step 4000, Minibatch Loss= 2623.9595, Training Accuracy= 0.967\n",
            "Step 4100, Minibatch Loss= 5476.4814, Training Accuracy= 0.933\n",
            "Step 4200, Minibatch Loss= 124.1974, Training Accuracy= 0.992\n",
            "Step 4300, Minibatch Loss= 1437.4878, Training Accuracy= 0.975\n",
            "Step 4400, Minibatch Loss= 4553.0850, Training Accuracy= 0.942\n",
            "Step 4500, Minibatch Loss= 997.3240, Training Accuracy= 0.967\n",
            "Step 4600, Minibatch Loss= 1089.4996, Training Accuracy= 0.975\n",
            "Step 4700, Minibatch Loss= 3100.5227, Training Accuracy= 0.950\n",
            "Step 4800, Minibatch Loss= 1375.5549, Training Accuracy= 0.967\n",
            "Step 4900, Minibatch Loss= 45.2206, Training Accuracy= 0.992\n",
            "Step 5000, Minibatch Loss= 86.4062, Training Accuracy= 0.992\n",
            "Step 5100, Minibatch Loss= 604.1240, Training Accuracy= 0.967\n",
            "Step 5200, Minibatch Loss= 2216.0359, Training Accuracy= 0.958\n",
            "Step 5300, Minibatch Loss= 2195.8904, Training Accuracy= 0.950\n",
            "Step 5400, Minibatch Loss= 1919.0618, Training Accuracy= 0.983\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Step 5500, Minibatch Loss= 174.9588, Training Accuracy= 0.975\n",
            "Step 5600, Minibatch Loss= 2402.7744, Training Accuracy= 0.950\n",
            "Step 5700, Minibatch Loss= 1578.2898, Training Accuracy= 0.950\n",
            "Step 5800, Minibatch Loss= 543.6522, Training Accuracy= 0.967\n",
            "Step 5900, Minibatch Loss= 918.3958, Training Accuracy= 0.967\n",
            "Step 6000, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
            "Step 6100, Minibatch Loss= 2267.0627, Training Accuracy= 0.958\n",
            "Step 6200, Minibatch Loss= 497.6160, Training Accuracy= 0.967\n",
            "Step 6300, Minibatch Loss= 120.2197, Training Accuracy= 0.983\n",
            "Step 6400, Minibatch Loss= 808.6403, Training Accuracy= 0.983\n",
            "Step 6500, Minibatch Loss= 2100.7190, Training Accuracy= 0.950\n",
            "Step 6600, Minibatch Loss= 286.0892, Training Accuracy= 0.983\n",
            "Step 6700, Minibatch Loss= 1522.1833, Training Accuracy= 0.967\n",
            "Step 6800, Minibatch Loss= 686.8840, Training Accuracy= 0.967\n",
            "Step 6900, Minibatch Loss= 583.4633, Training Accuracy= 0.967\n",
            "Step 7000, Minibatch Loss= 760.6177, Training Accuracy= 0.967\n",
            "Step 7100, Minibatch Loss= 1307.8708, Training Accuracy= 0.975\n",
            "Step 7200, Minibatch Loss= 2444.9182, Training Accuracy= 0.942\n",
            "Step 7300, Minibatch Loss= 0.0000, Training Accuracy= 1.000\n",
            "Step 7400, Minibatch Loss= 322.3267, Training Accuracy= 0.958\n",
            "Step 7500, Minibatch Loss= 212.3070, Training Accuracy= 0.983\n",
            "Step 7600, Minibatch Loss= 1390.7153, Training Accuracy= 0.942\n",
            "Step 7700, Minibatch Loss= 27.3360, Training Accuracy= 0.992\n",
            "Step 7800, Minibatch Loss= 410.4651, Training Accuracy= 0.975\n",
            "Step 7900, Minibatch Loss= 47.2476, Training Accuracy= 0.983\n",
            "Step 8000, Minibatch Loss= 328.9028, Training Accuracy= 0.975\n",
            "Step 8100, Minibatch Loss= 46.6818, Training Accuracy= 0.983\n",
            "Step 8200, Minibatch Loss= 287.4937, Training Accuracy= 0.950\n",
            "Step 8300, Minibatch Loss= 367.5380, Training Accuracy= 0.983\n",
            "Step 8400, Minibatch Loss= 576.3542, Training Accuracy= 0.958\n",
            "Step 8500, Minibatch Loss= 477.5480, Training Accuracy= 0.975\n",
            "Step 8600, Minibatch Loss= 734.4604, Training Accuracy= 0.975\n",
            "Step 8700, Minibatch Loss= 228.7093, Training Accuracy= 0.975\n",
            "Step 8800, Minibatch Loss= 68.3445, Training Accuracy= 0.983\n",
            "Step 8900, Minibatch Loss= 165.5614, Training Accuracy= 0.975\n",
            "Step 9000, Minibatch Loss= 193.4140, Training Accuracy= 0.975\n",
            "Step 9100, Minibatch Loss= 247.8687, Training Accuracy= 0.975\n",
            "Step 9200, Minibatch Loss= 121.6879, Training Accuracy= 0.967\n",
            "Step 9300, Minibatch Loss= 282.6566, Training Accuracy= 0.958\n",
            "Step 9400, Minibatch Loss= 199.1579, Training Accuracy= 0.992\n",
            "Step 9500, Minibatch Loss= 569.2713, Training Accuracy= 0.967\n",
            "Step 9600, Minibatch Loss= 61.9606, Training Accuracy= 0.992\n",
            "Step 9700, Minibatch Loss= 34.1626, Training Accuracy= 0.992\n",
            "Step 9800, Minibatch Loss= 16.5226, Training Accuracy= 0.992\n",
            "Step 9900, Minibatch Loss= 42.3427, Training Accuracy= 0.983\n",
            "Step 10000, Minibatch Loss= 19.9222, Training Accuracy= 0.992\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.96875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "69FjkJVRQf0P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "84e3ee4a-dfbd-4ba6-aacf-34bce0231abb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532535335108,
          "user_tz": -60,
          "elapsed": 441,
          "user": {
            "displayName": "shreya garge",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "113769829546482680202"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(sess.run(logits, feed_dict={X: np.expand_dims(mnist.test.images[1,:],0),keep_prob: 1.0}))\n",
        "# print(mnist.test.labels[1,:])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-14433.6     27472.553   59175.754  -14321.43   -31761.506  -13806.6455\n",
            "  -49276.55     1273.9042   6336.773    9501.764 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zHofCjX4QlfH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "f2c6e6ea-581b-40a0-98e7-20be5d20ff20",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532534919081,
          "user_tz": -60,
          "elapsed": 640,
          "user": {
            "displayName": "shreya garge",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "113769829546482680202"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "idx = 123 # change value to test different image\n",
        "pred = sess.run(tf.argmax(prediction,1), feed_dict={X: np.expand_dims(mnist.test.images[idx,:],0),keep_prob: 1.0})\n",
        "print (\"Prediction:\", pred, \"Actual:\",np.argmax(mnist.test.labels[idx,:],-1))#tf.argmax(np.expand_dims(mnist.test.labels[1],0))#\n",
        "\n",
        "plt.imshow(np.reshape(mnist.test.images[idx,:],(28,28)))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: [6] Actual: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f2e0f5de6d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfwVlNZpyDCo6AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f2e9380a400>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "erZb7bh_QtYj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "np.save('testim2.npy',mnist.test.images[15,:])\n",
        "files.download('testim2.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zOfD1D9AQ_iH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "np.save('weights1.npy',sess.run(weights['wc1']))\n",
        "files.download('weights1.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nW5XThlMREKM",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('weights2.npy',sess.run(weights['wc2']))\n",
        "files.download('weights2.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JiHYSVSRRJLt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('weights3.npy',sess.run(weights['wd1']))\n",
        "files.download('weights3.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rwxwVNtiRTri",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('weights4.npy',sess.run(weights['out']))\n",
        "files.download('weights4.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "029FnljMRXrz",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('bc1.npy',sess.run(biases['bc1']))\n",
        "files.download('bc1.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bjO-hPdLRbiF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('bc2.npy',sess.run(biases['bc2']))\n",
        "files.download('bc2.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dDNa0W7ERfls",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('bd1.npy',sess.run(biases['bd1']))\n",
        "files.download('bd1.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lyn6Xei1Rjff",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('bout.npy',sess.run(biases['out']))\n",
        "files.download('bout.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RqOEy_fU0_BR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 1343
        },
        "outputId": "b2e1e9a9-9a34-4f9f-cb0b-be4fd09fc79f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532092633962,
          "user_tz": -60,
          "elapsed": 441,
          "user": {
            "displayName": "shreya garge",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "113769829546482680202"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(sess.run(weights['wc1']))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[[-1.15479812e-01  4.16034967e-01 -4.00686592e-01  8.28465939e-01\n",
            "     5.19545019e-01]]\n",
            "\n",
            "  [[-2.59787321e-01  9.04210091e-01 -7.78959468e-02 -4.09770966e-01\n",
            "     1.81714550e-01]]\n",
            "\n",
            "  [[ 2.25485805e-02 -3.54892313e-02  3.57550025e-01  6.68362901e-02\n",
            "     4.74855304e-01]]\n",
            "\n",
            "  [[-5.02884239e-02  2.41878003e-01 -1.52268587e-02  1.19749762e-01\n",
            "    -1.00468755e+00]]\n",
            "\n",
            "  [[ 2.88923532e-01 -2.02378616e-01 -1.45098820e-01  3.28658134e-01\n",
            "     5.59653223e-01]]]\n",
            "\n",
            "\n",
            " [[[ 4.27955955e-01 -1.21412039e+00  1.00577474e+00 -1.27317637e-01\n",
            "    -5.35779953e-01]]\n",
            "\n",
            "  [[ 1.28767863e-01 -2.32767940e-01 -2.59762928e-02 -2.44712755e-02\n",
            "    -5.29364228e-01]]\n",
            "\n",
            "  [[ 1.80617824e-01 -6.16505086e-01 -5.18001199e-01  3.86687696e-01\n",
            "     1.09244987e-01]]\n",
            "\n",
            "  [[-5.69390535e-01  1.60222992e-01  4.18368548e-01 -5.78603506e-01\n",
            "     1.75292969e-01]]\n",
            "\n",
            "  [[ 1.95542634e-01  3.13383192e-01 -9.94491391e-03  1.08717859e-01\n",
            "    -3.71219009e-01]]]\n",
            "\n",
            "\n",
            " [[[-3.22702676e-01  1.57034242e+00 -1.69747323e-01 -4.93205748e-02\n",
            "     4.94472653e-01]]\n",
            "\n",
            "  [[-1.05036296e-01 -6.83993101e-01 -7.56524146e-01 -3.58214110e-01\n",
            "    -2.54033774e-01]]\n",
            "\n",
            "  [[ 1.94417760e-01  6.32994533e-01  6.24008179e-01  8.63677442e-01\n",
            "     1.13036537e+00]]\n",
            "\n",
            "  [[ 3.68542314e-01  5.38533032e-01 -1.50133297e-01 -2.33342960e-01\n",
            "    -1.83970422e-01]]\n",
            "\n",
            "  [[-2.20688641e-01 -5.83352149e-01 -1.29348680e-01 -2.42502943e-01\n",
            "     4.43299681e-01]]]\n",
            "\n",
            "\n",
            " [[[-4.86315638e-02 -7.36715138e-01  6.92482814e-02 -1.28317431e-01\n",
            "     4.41912422e-03]]\n",
            "\n",
            "  [[ 9.80412215e-02  6.28763676e-01  8.33568633e-01  2.38597184e-01\n",
            "     2.59734362e-01]]\n",
            "\n",
            "  [[-8.39311481e-02 -5.45080788e-02 -6.98780596e-01 -1.19694960e+00\n",
            "    -6.44672215e-01]]\n",
            "\n",
            "  [[-4.33961600e-01 -2.36237600e-01  1.09682143e-01  7.36549854e-01\n",
            "     2.74853855e-01]]\n",
            "\n",
            "  [[-4.62150931e-01  2.69434959e-01  1.19329043e-01  2.57432640e-01\n",
            "    -1.24512136e-01]]]\n",
            "\n",
            "\n",
            " [[[-9.24659614e-03 -1.85267739e-02 -5.14094055e-01  9.67636406e-02\n",
            "    -3.36781502e-01]]\n",
            "\n",
            "  [[ 3.80046099e-01 -1.09630346e+00  3.70401293e-01 -9.79939103e-02\n",
            "     1.14766217e-03]]\n",
            "\n",
            "  [[-8.96787524e-01  8.55810642e-01  2.14634478e-01  3.17889392e-01\n",
            "     2.12998509e-01]]\n",
            "\n",
            "  [[ 5.46717286e-01  2.51281977e-01 -3.91696572e-01  5.28632812e-02\n",
            "    -1.98028743e-01]]\n",
            "\n",
            "  [[ 3.09812725e-01 -3.66658688e-01  3.56457502e-01 -4.91407454e-01\n",
            "    -3.68050970e-02]]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Y2Ds18ad85SV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 2244
        },
        "outputId": "d6c66099-78ab-49f1-cd3e-cc1769bf2a6a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1532094609663,
          "user_tz": -60,
          "elapsed": 431,
          "user": {
            "displayName": "shreya garge",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "113769829546482680202"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(mnist.test.images[1,:])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.454902   0.4901961\n",
            " 0.67058825 1.         1.         0.5882353  0.3647059  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.6627451  0.9921569  0.9921569  0.9921569  0.9921569\n",
            " 0.9921569  0.9921569  0.854902   0.11764707 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.6627451  0.9921569\n",
            " 0.9921569  0.9921569  0.8352942  0.5568628  0.6901961  0.9921569\n",
            " 0.9921569  0.4784314  0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.20392159 0.9803922  0.9921569  0.8235295  0.1254902\n",
            " 0.04705883 0.         0.02352941 0.8078432  0.9921569  0.54901963\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.3019608\n",
            " 0.9843138  0.8235295  0.09803922 0.         0.         0.\n",
            " 0.4784314  0.9725491  0.9921569  0.25490198 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.12156864 0.07058824\n",
            " 0.         0.         0.         0.         0.8196079  0.9921569\n",
            " 0.9921569  0.25490198 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.45882356 0.9686275  0.9921569  0.77647066 0.03921569\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.29803923 0.9686275\n",
            " 0.9921569  0.9058824  0.24705884 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.5019608  0.9921569  0.9921569  0.5647059\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.6901961\n",
            " 0.96470594 0.9921569  0.62352943 0.04705883 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.09803922 0.9176471  0.9921569  0.91372555\n",
            " 0.13725491 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.77647066 0.9921569  0.9921569  0.5529412  0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.30588236 0.9725491  0.9921569\n",
            " 0.7411765  0.04705883 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.07450981 0.7843138  0.9921569  0.9921569  0.5529412  0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.5254902  0.9921569\n",
            " 0.9921569  0.6784314  0.04705883 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.9725491  0.9921569  0.9921569  0.09803922\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.9725491  0.9921569  0.9921569  0.16862746 0.07843138 0.07843138\n",
            " 0.07843138 0.07843138 0.01960784 0.         0.01960784 0.07843138\n",
            " 0.07843138 0.14509805 0.5882353  0.5882353  0.5882353  0.5764706\n",
            " 0.03921569 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.9725491  0.9921569\n",
            " 0.9921569  0.9921569  0.9921569  0.9921569  0.9921569  0.9921569\n",
            " 0.65882355 0.56078434 0.6509804  0.9921569  0.9921569  0.9921569\n",
            " 0.9921569  0.9921569  0.9921569  0.9921569  0.48235297 0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.68235296 0.9921569  0.9921569  0.9921569\n",
            " 0.9921569  0.9921569  0.9921569  0.9921569  0.9921569  0.9921569\n",
            " 0.9921569  0.9921569  0.97647065 0.9686275  0.9686275  0.6627451\n",
            " 0.45882356 0.45882356 0.22352943 0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.46274513 0.48235297 0.48235297 0.48235297 0.6509804\n",
            " 0.9921569  0.9921569  0.9921569  0.60784316 0.48235297 0.48235297\n",
            " 0.16078432 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}