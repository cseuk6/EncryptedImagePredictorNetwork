{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "training_net.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "6EB2Yn5CMbKd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3e588eed-8bac-4534-f5e1-63c3f589e617",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531822311708,
          "user_tz": -60,
          "elapsed": 1020,
          "user": {
            "displayName": "shreya garge",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "113769829546482680202"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Import MNIST data\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9eB5xvW3MmGB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        " # Training Parameters\n",
        "learning_rate = 0.001\n",
        "num_steps = 500\n",
        "batch_size = 128\n",
        "display_step = 10\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 784 # MNIST data input (img shape: 28*28)\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "dropout = 0.75 # Dropout, probability to keep units\n",
        "\n",
        "# tf Graph input\n",
        "X = tf.placeholder(tf.float32, [None, num_input])\n",
        "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
        "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jdkac1eWMnal",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Create some wrappers for simplicity\n",
        "def conv2d(x, W, b, strides=1):\n",
        "    # Conv2D wrapper, with bias and relu activation\n",
        "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
        "    x = tf.nn.bias_add(x, b)\n",
        "    return x\n",
        "\n",
        "\n",
        "def meanpool2d(x, k=2):\n",
        "    \n",
        "    return tf.nn.avg_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
        "                          padding='SAME')\n",
        "\n",
        "\n",
        "# Create model\n",
        "def conv_net(x, weights, biases, dropout):\n",
        "    # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
        "    # Reshape to match picture format [Height x Width x Channel]\n",
        "    # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
        "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv1_ = conv2d(x, weights['wc1'], biases['bc1'])\n",
        "#     with sess.as_default():\n",
        "#         print(conv1.eval())\n",
        "#         print(\"   /n/n\")\n",
        "    \n",
        "    # Max Pooling (down-sampling)\n",
        "    conv1 = meanpool2d(conv1_, k=2)\n",
        "\n",
        "    # Convolution Layer\n",
        "    conv2_ = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
        "    # Max Pooling (down-sampling)\n",
        "    conv2 = meanpool2d(conv2_, k=2)\n",
        "    # Fully connected layer\n",
        "    # Reshape conv2 output to fit fully connected layer input\n",
        "    fc1_ = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "    fc1 = tf.add(tf.matmul(fc1_, weights['wd1']), biases['bd1'])\n",
        "    #fc1 = tf.nn.relu(fc1)\n",
        "    # Apply Dropout\n",
        "    fc1_2 = tf.nn.dropout(fc1, dropout)\n",
        "    \n",
        "    check = {}\n",
        "    check['conv1'] = conv1_\n",
        "    check['conv1mp'] = conv1\n",
        "    check['conv2'] = conv2_\n",
        "    check['conv2mp'] = conv2\n",
        "    check['fc1_reshape'] = fc1_\n",
        "    check['fc1_wb'] = fc1\n",
        "    check['fc1_drp'] = fc1_2\n",
        "\n",
        "    # Output, class prediction\n",
        "    out = tf.add(tf.matmul(fc1_2, weights['out']), biases['out'])\n",
        "    return out, check"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QbTGoSeQMrfF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Store layers weight & bias\n",
        "weights = {\n",
        "    # 5x5 conv, 1 input, 32 outputs\n",
        "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
        "    # 5x5 conv, 32 inputs, 64 outputs\n",
        "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
        "    #'wc3': tf.Variable(tf.random_normal([5, 5, 48, 64])),\n",
        "    # fully connected, 7*7*64 inputs, 1024 outputs\n",
        "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
        "    # 1024 inputs, 10 outputs (class prediction)\n",
        "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
        "}\n",
        "\n",
        "biases = {\n",
        "    'bc1': tf.Variable(tf.random_normal([32])),\n",
        "    'bc2': tf.Variable(tf.random_normal([64])),\n",
        "    #'bc3': tf.Variable(tf.random_normal([64])),\n",
        "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
        "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
        "}\n",
        "\n",
        "# Construct model\n",
        "logits,verify = conv_net(X, weights, biases, keep_prob)\n",
        "prediction = tf.nn.softmax(logits)\n",
        "\n",
        "# Define loss and optimizer\n",
        "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
        "    logits=logits, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "\n",
        "\n",
        "# Evaluate model\n",
        "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "\n",
        "\n",
        "sess = tf.Session()\n",
        "# Initialize the variables (i.e. assign their default value)\n",
        "init = tf.global_variables_initializer()\n",
        "# Run the initializer\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cQ3RjyxlMw5q",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "f1d9216a-f0b7-4578-90fa-241e3703ab2f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531822333440,
          "user_tz": -60,
          "elapsed": 7246,
          "user": {
            "displayName": "shreya garge",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "113769829546482680202"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Start training\n",
        "import numpy as np\n",
        "for step in range(1, num_steps+1):\n",
        "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
        "        # Run optimization op (backprop)\n",
        "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
        "        if step % display_step == 0 or step == 1:\n",
        "            # Calculate batch loss and accuracy\n",
        "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
        "                                                                 Y: batch_y,\n",
        "                                                                 keep_prob: 1.0})\n",
        "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
        "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
        "                  \"{:.3f}\".format(acc))\n",
        "\n",
        "print(\"Optimization Finished!\")\n",
        "\n",
        "# Calculate accuracy for 256 MNIST test images\n",
        "print(\"Testing Accuracy:\", \\\n",
        "    sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
        "                                  Y: mnist.test.labels[:256],\n",
        "                                  keep_prob: 1.0}))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Step 1, Minibatch Loss= 98186.2422, Training Accuracy= 0.078\n",
            "Step 10, Minibatch Loss= 40360.4375, Training Accuracy= 0.258\n",
            "Step 20, Minibatch Loss= 11813.3145, Training Accuracy= 0.617\n",
            "Step 30, Minibatch Loss= 6611.5552, Training Accuracy= 0.758\n",
            "Step 40, Minibatch Loss= 8685.6875, Training Accuracy= 0.812\n",
            "Step 50, Minibatch Loss= 3876.0322, Training Accuracy= 0.836\n",
            "Step 60, Minibatch Loss= 4041.7061, Training Accuracy= 0.859\n",
            "Step 70, Minibatch Loss= 4593.1719, Training Accuracy= 0.812\n",
            "Step 80, Minibatch Loss= 3060.7913, Training Accuracy= 0.906\n",
            "Step 90, Minibatch Loss= 2543.2065, Training Accuracy= 0.891\n",
            "Step 100, Minibatch Loss= 4327.8271, Training Accuracy= 0.898\n",
            "Step 110, Minibatch Loss= 5263.9189, Training Accuracy= 0.828\n",
            "Step 120, Minibatch Loss= 4490.6333, Training Accuracy= 0.867\n",
            "Step 130, Minibatch Loss= 7390.7905, Training Accuracy= 0.820\n",
            "Step 140, Minibatch Loss= 1925.0941, Training Accuracy= 0.914\n",
            "Step 150, Minibatch Loss= 6931.4224, Training Accuracy= 0.844\n",
            "Step 160, Minibatch Loss= 3515.3623, Training Accuracy= 0.875\n",
            "Step 170, Minibatch Loss= 2172.6711, Training Accuracy= 0.938\n",
            "Step 180, Minibatch Loss= 4235.3174, Training Accuracy= 0.859\n",
            "Step 190, Minibatch Loss= 3003.4050, Training Accuracy= 0.906\n",
            "Step 200, Minibatch Loss= 3498.6421, Training Accuracy= 0.883\n",
            "Step 210, Minibatch Loss= 3268.4497, Training Accuracy= 0.898\n",
            "Step 220, Minibatch Loss= 4153.3555, Training Accuracy= 0.852\n",
            "Step 230, Minibatch Loss= 3615.6689, Training Accuracy= 0.883\n",
            "Step 240, Minibatch Loss= 3560.7534, Training Accuracy= 0.906\n",
            "Step 250, Minibatch Loss= 5328.1597, Training Accuracy= 0.898\n",
            "Step 260, Minibatch Loss= 3118.6270, Training Accuracy= 0.898\n",
            "Step 270, Minibatch Loss= 5134.1123, Training Accuracy= 0.852\n",
            "Step 280, Minibatch Loss= 4242.4639, Training Accuracy= 0.844\n",
            "Step 290, Minibatch Loss= 2437.7124, Training Accuracy= 0.938\n",
            "Step 300, Minibatch Loss= 3820.9900, Training Accuracy= 0.875\n",
            "Step 310, Minibatch Loss= 8386.0078, Training Accuracy= 0.852\n",
            "Step 320, Minibatch Loss= 1710.6057, Training Accuracy= 0.922\n",
            "Step 330, Minibatch Loss= 1390.7811, Training Accuracy= 0.906\n",
            "Step 340, Minibatch Loss= 4656.1367, Training Accuracy= 0.859\n",
            "Step 350, Minibatch Loss= 5015.8535, Training Accuracy= 0.867\n",
            "Step 360, Minibatch Loss= 2984.5063, Training Accuracy= 0.867\n",
            "Step 370, Minibatch Loss= 4440.3848, Training Accuracy= 0.891\n",
            "Step 380, Minibatch Loss= 4795.9805, Training Accuracy= 0.867\n",
            "Step 390, Minibatch Loss= 5441.0371, Training Accuracy= 0.859\n",
            "Step 400, Minibatch Loss= 2158.2114, Training Accuracy= 0.914\n",
            "Step 410, Minibatch Loss= 1488.0686, Training Accuracy= 0.938\n",
            "Step 420, Minibatch Loss= 4844.1821, Training Accuracy= 0.875\n",
            "Step 430, Minibatch Loss= 1919.6351, Training Accuracy= 0.930\n",
            "Step 440, Minibatch Loss= 3789.2910, Training Accuracy= 0.898\n",
            "Step 450, Minibatch Loss= 3589.4326, Training Accuracy= 0.914\n",
            "Step 460, Minibatch Loss= 4497.7588, Training Accuracy= 0.844\n",
            "Step 470, Minibatch Loss= 1994.2798, Training Accuracy= 0.898\n",
            "Step 480, Minibatch Loss= 2459.7231, Training Accuracy= 0.898\n",
            "Step 490, Minibatch Loss= 2344.7612, Training Accuracy= 0.922\n",
            "Step 500, Minibatch Loss= 3034.0898, Training Accuracy= 0.844\n",
            "Optimization Finished!\n",
            "Testing Accuracy: 0.91796875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "C7eW407lOXYL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f78cca22-9cdc-4647-ba18-a0308530ad0f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531839678215,
          "user_tz": -60,
          "elapsed": 1398,
          "user": {
            "displayName": "shreya garge",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "113769829546482680202"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(sess.run(logits, feed_dict={X: np.expand_dims(mnist.test.images[1,:],0),keep_prob: 1.0}))\n",
        "# print(mnist.test.labels[1,:])"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[  41364.598  -12751.213  106725.44    22771.99  -143177.05    66472.21\n",
            "    55097.516 -234983.45    18313.836 -130417.39 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PdMfBEjBOqoj",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "e9f715cc-57a6-4a71-d929-eda0a6cf6339",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1531840593593,
          "user_tz": -60,
          "elapsed": 1073,
          "user": {
            "displayName": "shreya garge",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "113769829546482680202"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "%matplotlib inline\n",
        "idx = 15 # change value to test different image\n",
        "pred = sess.run(tf.argmax(prediction,1), feed_dict={X: np.expand_dims(mnist.test.images[idx,:],0),keep_prob: 1.0})\n",
        "print (\"Prediction:\", pred, \"Actual:\",np.argmax(mnist.test.labels[idx,:],-1))#tf.argmax(np.expand_dims(mnist.test.labels[1],0))#\n",
        "\n",
        "plt.imshow(np.reshape(mnist.test.images[idx,:],(28,28)))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: [5] Actual: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f7f0f9ee4a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f7f28b89748>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ugUpA6ZTySa1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "np.save('testim2.npy',mnist.test.images[15,:])\n",
        "files.download('testim2.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "56HqLRiJOvxi",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "np.save('weights1.npy',sess.run(weights['wc1']))\n",
        "files.download('weights1.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZRsXeVnHViV5",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('weights2.npy',sess.run(weights['wc2']))\n",
        "files.download('weights2.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FLNGqyGKVkVr",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('weights3.npy',sess.run(weights['wd1']))\n",
        "files.download('weights3.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5YqZ4L1VmYG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('weights4.npy',sess.run(weights['out']))\n",
        "files.download('weights4.npy') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DfHOCr4yVoWm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('bc1.npy',sess.run(biases['bc1']))\n",
        "files.download('bc1.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2YuwM9QVp34",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('bc2.npy',sess.run(biases['bc2']))\n",
        "files.download('bc2.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x2PJcpl1VrRs",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('bd1.npy',sess.run(biases['bd1']))\n",
        "files.download('bd1.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7QSewgbeVs_W",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "np.save('bout.npy',sess.run(biases['out']))\n",
        "files.download('bout.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}